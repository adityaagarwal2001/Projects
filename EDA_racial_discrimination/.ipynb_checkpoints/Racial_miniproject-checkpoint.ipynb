{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = data[data.race=='w']\n",
    "black = data[data.race=='b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makred white\n",
      " - number of resumes:  2435\n",
      " - number of callbacks:  235\n",
      " - callback ratio:  0.0965\n",
      "\n",
      "Makred black\n",
      " - number of resumes:  2435\n",
      " - number of callbacks:  157\n",
      " - callback ratio:  0.0645\n"
     ]
    }
   ],
   "source": [
    "print('Makred white')\n",
    "print(' - number of resumes: ', white.shape[0])\n",
    "print(' - number of callbacks: ', int(white['call'].sum()))\n",
    "print(' - callback ratio: ', round(int(white['call'].sum())/white.shape[0], 4))\n",
    "\n",
    "print('\\nMakred black')\n",
    "print(' - number of resumes: ', black.shape[0])\n",
    "print(' - number of callbacks: ', int(black['call'].sum()))\n",
    "print(' - callback ratio: ', round(int(black['call'].sum())/black.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample size is large. Though the current callback distribution is binomial as number of observations become large, standardized sample means are normally distributed and since actual population **n** would tend towards **infinite** (i.e. a lot of resumes in the real world), *CLT applies*. \n",
    "\n",
    "Two data sets where wee could just compare the sample means in a **2 sample t-test**. Test statistics will be **difference in callback means**, which is same as difference in callback ratio as number of entires is same for each 'b' and 'w' dataset. \n",
    "\n",
    "But first let's try bootstrap hypothesis test by drawing random instances from original data and assign to white and black bootstrap samples. I will calculate the difference in means from bootstrap samples and test if the difference is at least as large as the original difference.\n",
    "\n",
    "**Null Hypothesis:** There is no difference in callback ratio for resumes marked white or black.\n",
    "\n",
    "**Alternate Hypothesis:** Race influence on resume callbacks is statistically significant.\n",
    "\n",
    "**Test statistic:** Difference in means of callbacks for 'w' and 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = white[['race', 'call']]\n",
    "black = black[['race', 'call']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_replicate_1d(data, func):\n",
    "    bs_sample = np.random.choice(data, size=len(data))\n",
    "    return func(bs_sample)\n",
    "\n",
    "def draw_bs_reps(data1, func, size=1):\n",
    "    bs_replicates = np.empty(size)\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
    "    return bs_replicates\n",
    "\n",
    "def diff_of_means(data1, data2):\n",
    "    return (np.mean(data1) - np.mean(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOTSTRAP\n",
      "\n",
      "Difference in call back ratio:  0.032032855\n",
      "T statistics:  4.114705290861751\n",
      "pvalue:  0.0\n",
      "Margin of error:  0.015258540060051217\n",
      "Confidence interval:  [0.01677431 0.04729139]\n"
     ]
    }
   ],
   "source": [
    "# Test statistic difference of means\n",
    "\n",
    "original_diff_means = diff_of_means(white.call, black.call)\n",
    "\n",
    "# Initialize bootstrap replicates: bs_replicates\n",
    "bs_replicates = np.empty(10000)\n",
    "\n",
    "for i in range(10000):\n",
    "    # Generate bootstrap sample\n",
    "    bs_sample = np.random.choice(data.call, size=len(data.call))\n",
    "    \n",
    "    # Compute replicate\n",
    "    bs_replicates[i] = diff_of_means(bs_sample[:len(white)],\n",
    "                                     bs_sample[len(black):])\n",
    "\n",
    "# Compute and print p-value: p\n",
    "p = np.sum(bs_replicates >= original_diff_means) / len(bs_replicates)\n",
    "\n",
    "# Variance for two samples, white and black\n",
    "var_2samp = (white.call.var()/len(white)) + (black.call.var()/len(black))\n",
    "\n",
    "# Standard error\n",
    "std_dev = np.sqrt(var_2samp)\n",
    "\n",
    "# t statistic\n",
    "t_stat = (white.call.mean() - black.call.mean()) / std_dev\n",
    "\n",
    "# Margin of error with 95% confidence\n",
    "margin_error = 1.96 * std_dev\n",
    "\n",
    "# Confidence interval\n",
    "conf_interval = original_diff_means + np.array([-1, 1]) * margin_error\n",
    "\n",
    "print('BOOTSTRAP')\n",
    "print('\\nDifference in call back ratio: ', original_diff_means)\n",
    "print('T statistics: ', t_stat)\n",
    "print('pvalue: ', p)\n",
    "print('Margin of error: ', margin_error)\n",
    "print('Confidence interval: ', conf_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 sample T test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T - test\n",
      "\n",
      "Difference in call back ratio:  0.032032855\n",
      "T statistics:  4.114705290861751\n",
      "pvalue:  3.940802103128886e-05\n",
      "Margin of error:  0.015258540060051217\n",
      "Confidence interval:  (0.016774595174263628, 0.04729111453585753)\n"
     ]
    }
   ],
   "source": [
    "# Run a T test with difference of means for white and black datasets\n",
    "\n",
    "t_ttest = stats.ttest_ind(white.call, black.call)[0]\n",
    "p_ttest = stats.ttest_ind(white.call, black.call)[1]\n",
    "\n",
    "# Differnece in means for white and black datasets will be normally distributed\n",
    "# Std deviation will be the sum of two datasets\n",
    "\n",
    "# Variance for two samples, white and black\n",
    "var_2samp = (white.call.var()/len(white)) + (black.call.var()/len(black))\n",
    "\n",
    "# Standard error\n",
    "std_dev = np.sqrt(var_2samp)\n",
    "margin_ttest = 1.96 * std_dev\n",
    "# 95% confidence interval\n",
    "conf_interval = stats.norm.interval(0.95, loc=original_diff_means, scale=std_dev)\n",
    "\n",
    "print('T - test')\n",
    "print('\\nDifference in call back ratio: ', original_diff_means)\n",
    "print('T statistics: ', t_ttest)\n",
    "print('pvalue: ', p_ttest)\n",
    "print('Margin of error: ', margin_ttest)\n",
    "print('Confidence interval: ', conf_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Summary\n",
    "\n",
    "Write a story describing the statistical significance in the context or the original problem.\n",
    "Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The callback ratio is higher by 3.2% points in resumes marked *white*. Our null hypothesis that the difference is by chance was rejected as the pvalue of 3.9e-05 is very small, confirming that this difference is not due to mere random chance. \n",
    "\n",
    "It can be concluded, race plays an important factor towards job prospects. However, this analysis does not take into consideration other factors which would influence a resume call back. Also, it does not weigh race as a factor compared to others. Education, experience, additional skills, etc. would be important in decision making as well.\n",
    "\n",
    "I would look at all the available features in the data set and find correlation with call value wherever applicable. Strong correlation does not suggest causation. Thus, I would want to conduct multiple hypothesis tests for features with strong correlation. Regression analysis would come in handy to explain the effects of changes in feature values and success. As we know call feature aka as dependent variable is binary, **logistic regression** would be the best approach.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
